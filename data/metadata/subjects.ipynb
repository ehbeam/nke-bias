{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18155"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmids = sorted(list(pd.read_csv(\"../brain/coordinates.csv\")[\"PMID\"]))\n",
    "len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"PMID\": pmids})\n",
    "df[\"N\"] = \"\"\n",
    "df[\"SOURCE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data from BrainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['// Anderson N D, 2000: FA, Encoding > Retrieval in Young\\n// Subjects=12\\n1.7\\t-6.74\\t45.36\\n-52.9\\t41.22\\t10.17\\n-44.06\\t18.68\\t21.21\\n-46.76\\t40.87\\t-16.8\\n-50.8\\t-48.9\\t-12.33\\n-31.8\\t9.07\\t-36.32\\n59.43\\t17.38\\t1.65\\n57.49\\t5.86\\t16.27\\n65.88\\t-2.57\\t-5.45\\n56.92\\t5.96\\t-28.56\\n20.78\\t-59.75\\t5.45\\n40.13\\t-95.37\\t-9.28\\n13.86\\t-21.43\\t-20.63\\n-35.58\\t45.95\\t13.89\\n-52.67\\t-35.77\\t13.3\\n-41.76\\t-61.26\\t15.63\\n-57.43\\t-10.63\\t-16\\n-42.44\\t-18.2\\t-28.96\\n-52.43\\t-38.37\\t31.48\\n-26.68\\t-94.36\\t5.21\\n46.68\\t-68.58\\t1.4\\n39.61\\t-18.33\\t-34.82\\n38.47\\t-32.55\\t42.8',\n",
       " '// Anderson N D, 2000: FA, Retrieval > Encoding in Young\\n// Subjects=12\\n-27.39\\t60.09\\t-19.03\\n-16.33\\t53.28\\t-.62\\n-11.43\\t-53.94\\t23.36\\n-9.27\\t-97.72\\t14.21\\n42.09\\t47.52\\t3.44\\n7.67\\t52.9\\t16.94\\n16.12\\t-62.25\\t-21.11\\n1.29\\t-18.57\\t10.68\\n-14.5\\t33.36\\t-30.05\\n-3.11\\t44.35\\t17.97\\n-37.97\\t15.8\\t-9.98\\n-6.93\\t-70.11\\t33.85\\n-5.31\\t-78.52\\t-10.17\\n-20.64\\t5.22\\t-9.23\\n22.28\\t22.86\\t-29.64\\n15.95\\t56.82\\t-10.48\\n35.45\\t13.51\\t-15.49\\n3.88\\t-70.08\\t33.66\\n.97\\t-40.62\\t-18.51',\n",
       " '// Anderson N D, 2000: FA > DA (Encoding) in Young\\n// Subjects=12\\n-54.69\\t17.76\\t34.93\\n-42.48\\t-22.87\\t-32.98\\n-5.48\\t9.94\\t-5.48\\n-13.77\\t-110.04\\t-2.43\\n46.47\\t32.64\\t4.84\\n5.15\\t41.47\\t-13.26\\n41.75\\t-14.07\\t-35.28\\n63.84\\t-49.79\\t-5.23\\n18.11\\t-17.58\\t-25.57\\n-33.84\\t20.95\\t-24.01\\n-50.93\\t44.23\\t-3.61\\n-3.24\\t65.21\\t11.43\\n-26.56\\t22.53\\t38.46\\n-26.99\\t-44.14\\t-8.72\\n-57.24\\t-59.55\\t-11.17\\n31.07\\t28.39\\t-16.89\\n31.5\\t-97.53\\t-8.92\\n12.1\\t-64.45\\t1.58']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_coords = open(\"brainmap_coords_180803.txt\", \"r\").read().split(\"\\n\\n\")\n",
    "bm_coords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAINMAP_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>KEY</th>\n",
       "      <th>1st_AUTHOR</th>\n",
       "      <th>AUTHORS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>PAGES</th>\n",
       "      <th>BEHAVIORAL_DOMAIN</th>\n",
       "      <th>EXPERIMENT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>ABSTRACT_URL</th>\n",
       "      <th>NUM_COORDINATES</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16050115</td>\n",
       "      <td>12953303</td>\n",
       "      <td>Aasen I, 2003</td>\n",
       "      <td>Aasen I</td>\n",
       "      <td>Aasen I|Hashimoto Y|Sakai K L</td>\n",
       "      <td>2003</td>\n",
       "      <td>Brain activations during conscious self-monito...</td>\n",
       "      <td>Human Brain Mapping</td>\n",
       "      <td>20</td>\n",
       "      <td>Sep</td>\n",
       "      <td>22-28</td>\n",
       "      <td>['Cognition.Language.Speech', 'Cognition.Langu...</td>\n",
       "      <td>['Brain Regions Selectively Associated with th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>19</td>\n",
       "      <td>10.1002/hbm.10119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7110338</td>\n",
       "      <td>15858160</td>\n",
       "      <td>Abe N, 2006</td>\n",
       "      <td>Abe N</td>\n",
       "      <td>Abe N|Suzuki M|Tsukiura T|Mori E|Yamaguchi K|I...</td>\n",
       "      <td>2006</td>\n",
       "      <td>Dissociable roles of prefrontal and anterior c...</td>\n",
       "      <td>Cerebral Cortex</td>\n",
       "      <td>16</td>\n",
       "      <td>Feb</td>\n",
       "      <td>192-199</td>\n",
       "      <td>['Cognition.Social Cognition']</td>\n",
       "      <td>['(Lie, Old - Truth, Old) + (Lie, New - Truth,...</td>\n",
       "      <td>Subjects underwent 4 conditions in which they ...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.1093/cercor/bhi097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7110339</td>\n",
       "      <td>17280517</td>\n",
       "      <td>Abe N, 2007</td>\n",
       "      <td>Abe N</td>\n",
       "      <td>Abe N|Suzuki M|Mori E|Itoh M|Fujii T</td>\n",
       "      <td>2007</td>\n",
       "      <td>Deceiving others: Distinct neural responses of...</td>\n",
       "      <td>Journal of Cognitive Neuroscience</td>\n",
       "      <td>19</td>\n",
       "      <td>Feb</td>\n",
       "      <td>287-295</td>\n",
       "      <td>['Cognition.Social Cognition,Emotion.Negative....</td>\n",
       "      <td>['Main Effect of Falsifying the Truthful Respo...</td>\n",
       "      <td>Subjects underwent 4 conditions in which they ...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.1162/jocn.2007.19.2.287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRAINMAP_ID      PMID            KEY 1st_AUTHOR  \\\n",
       "0     16050115  12953303  Aasen I, 2003    Aasen I   \n",
       "1      7110338  15858160    Abe N, 2006      Abe N   \n",
       "2      7110339  17280517    Abe N, 2007      Abe N   \n",
       "\n",
       "                                             AUTHORS  YEAR  \\\n",
       "0                      Aasen I|Hashimoto Y|Sakai K L  2003   \n",
       "1  Abe N|Suzuki M|Tsukiura T|Mori E|Yamaguchi K|I...  2006   \n",
       "2               Abe N|Suzuki M|Mori E|Itoh M|Fujii T  2007   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0  Brain activations during conscious self-monito...   \n",
       "1  Dissociable roles of prefrontal and anterior c...   \n",
       "2  Deceiving others: Distinct neural responses of...   \n",
       "\n",
       "                             JOURNAL VOLUME MONTH    PAGES  \\\n",
       "0                Human Brain Mapping     20   Sep    22-28   \n",
       "1                    Cerebral Cortex     16   Feb  192-199   \n",
       "2  Journal of Cognitive Neuroscience     19   Feb  287-295   \n",
       "\n",
       "                                   BEHAVIORAL_DOMAIN  \\\n",
       "0  ['Cognition.Language.Speech', 'Cognition.Langu...   \n",
       "1                     ['Cognition.Social Cognition']   \n",
       "2  ['Cognition.Social Cognition,Emotion.Negative....   \n",
       "\n",
       "                                          EXPERIMENT  \\\n",
       "0  ['Brain Regions Selectively Associated with th...   \n",
       "1  ['(Lie, Old - Truth, Old) + (Lie, New - Truth,...   \n",
       "2  ['Main Effect of Falsifying the Truthful Respo...   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0                                                NaN   \n",
       "1  Subjects underwent 4 conditions in which they ...   \n",
       "2  Subjects underwent 4 conditions in which they ...   \n",
       "\n",
       "                                        ABSTRACT_URL  NUM_COORDINATES  \\\n",
       "0  http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...               19   \n",
       "1  http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...                4   \n",
       "2  http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?...               12   \n",
       "\n",
       "                          DOI  \n",
       "0           10.1002/hbm.10119  \n",
       "1       10.1093/cercor/bhi097  \n",
       "2  10.1162/jocn.2007.19.2.287  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_df = pd.read_csv(\"brainmap_metadata_180809.csv\", encoding=\"latin-1\")\n",
    "bm_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_n = {}\n",
    "for study in bm_coords:\n",
    "    key = study.split(\":\")[0].replace(\"// \", \"\")\n",
    "    if \"Subjects=\" in study:\n",
    "        n = float(study.split(\"Subjects=\")[1].split(\"\\n\")[0])\n",
    "        if key in bm_n.keys():\n",
    "            bm_n[key].append(n)\n",
    "        else:\n",
    "            bm_n[key] = [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm2pmid = {row[\"KEY\"]: row[\"PMID\"] for i, row in bm_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaywitz B A, 1995\n",
      "Bookheimer S Y, 1995\n",
      "Awh E, 1996\n",
      "de Araujo I E, 2003b\n",
      "De Bleser R, 2003\n",
      "Bartels A, 2000b\n",
      "De Nil L F, 2008\n",
      "Gilger J W, 2013\n",
      "Morita T, 2016\n",
      "Ishitobi M, 2011\n",
      "Lundström J N, 2008\n",
      "Kisely M, 2001\n",
      "Herrington J D, 2007\n",
      "Kucian K, 2005\n",
      "Owens T E, 2010\n"
     ]
    }
   ],
   "source": [
    "for key, n in bm_n.items():\n",
    "    mean_n = sum(n) / len(n)\n",
    "    if key in bm2pmid.keys():\n",
    "        pmid = bm2pmid[key]\n",
    "        df.loc[df[\"PMID\"] == pmid, \"N\"] = mean_n\n",
    "        df.loc[df[\"PMID\"] == pmid, \"SOURCE\"] = \"BrainMap\"\n",
    "        found.append(pmid)\n",
    "    else:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data collected manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>MODALITY</th>\n",
       "      <th>MODALITY_CATEGORY</th>\n",
       "      <th>AGE_MIN</th>\n",
       "      <th>AGE_MAX</th>\n",
       "      <th>AGE_MEAN</th>\n",
       "      <th>AGE_SD</th>\n",
       "      <th>N_FEMALE</th>\n",
       "      <th>N_MALE</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27894900</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Functional MRI</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22922525</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Functional MRI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.2</td>\n",
       "      <td>6.10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17336346</td>\n",
       "      <td>fMRI</td>\n",
       "      <td>Functional MRI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.7</td>\n",
       "      <td>10.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID MODALITY MODALITY_CATEGORY  AGE_MIN  AGE_MAX  AGE_MEAN  AGE_SD  \\\n",
       "0  27894900     fMRI    Functional MRI     18.0     28.0      21.9     NaN   \n",
       "1  22922525     fMRI    Functional MRI      NaN      NaN      33.2    6.10   \n",
       "2  17336346     fMRI    Functional MRI      NaN      NaN      25.7   10.15   \n",
       "\n",
       "   N_FEMALE  N_MALE     N  \n",
       "0      11.0     6.0  17.0  \n",
       "1      12.0    15.0  27.0  \n",
       "2       NaN     NaN  20.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = pd.read_csv(\"ehb_nrsa.csv\")\n",
    "demo = demo.dropna(subset=[\"N\"])\n",
    "demo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in demo.iterrows():\n",
    "    pmid = row[\"PMID\"]\n",
    "    if pmid not in found:\n",
    "        df.loc[df[\"PMID\"] == pmid, \"N\"] = row[\"N\"]\n",
    "        df.loc[df[\"PMID\"] == pmid, \"SOURCE\"] = \"EHB\"\n",
    "        found.append(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>N</th>\n",
       "      <th>SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>9065511</td>\n",
       "      <td>4.0</td>\n",
       "      <td>EHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>9114263</td>\n",
       "      <td>3.0</td>\n",
       "      <td>EHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9185551</td>\n",
       "      <td>15.5</td>\n",
       "      <td>EHB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PMID     N SOURCE\n",
       "112  9065511   4.0    EHB\n",
       "118  9114263   3.0    EHB\n",
       "131  9185551  15.5    EHB"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehb = pd.read_csv(\"ehb_subjects.csv\")\n",
    "ehb = ehb.loc[ehb[\"SOURCE\"] == \"EHB\"]\n",
    "ehb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in ehb.iterrows():\n",
    "    pmid = row[\"PMID\"]\n",
    "    if pmid not in found:\n",
    "        df.loc[df[\"PMID\"] == pmid, \"N\"] = row[\"N\"]\n",
    "        df.loc[df[\"PMID\"] == pmid, \"SOURCE\"] = \"EHB\"\n",
    "        found.append(pmid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data by string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_patterns = [r\"(?<=[nN]\\s\\=\\s)\\d+\",\n",
    "                    r\"(?<=[nN]\\=)\\d+\",\n",
    "                    r\"\\w+(?=\\s+healthy)\",\n",
    "                    r\"\\w+(?=\\s+normal)\",\n",
    "                    r\"\\w+(?=\\s+human)\",\n",
    "                    r\"\\w+(?=\\s+young)\",\n",
    "                    r\"\\w+(?=\\s+righthanded)\", \n",
    "                    r\"\\w+(?=\\s+matched)\", \n",
    "                    r\"\\w+(?=\\s+age)\",\n",
    "                    r\"\\w+(?=\\s+sex)\",\n",
    "                    r\"\\w+(?=\\s+gender)\",\n",
    "                    r\"\\w+(?=\\s+english)\",\n",
    "                    r\"\\w+(?=\\s+native)\",\n",
    "                    r\"\\w+(?=\\s+demographically)\",\n",
    "                    r\"\\w+(?=\\s+neurologically)\",\n",
    "                    r\"\\w+(?=\\s+congenitally)\",\n",
    "                    r\"\\w+(?=\\s+typically)\",\n",
    "                    r\"\\w+(?=\\s+neurotypical)\",\n",
    "                    r\"\\w+(?=\\s+subject)\",\n",
    "                    r\"\\w+(?=\\s+participant)\", \n",
    "                    r\"\\w+(?=\\s+volunteer)\",\n",
    "                    r\"\\w+(?=\\s+observer)\",\n",
    "                    r\"\\w+(?=\\s+perceiver)\",\n",
    "                    r\"\\w+(?=\\s+listener)\",\n",
    "                    r\"\\w+(?=\\s+blind)\",\n",
    "                    r\"\\w+(?=\\s+deaf)\",\n",
    "                    r\"\\w+(?=\\s+individual)\",\n",
    "                    r\"\\w+(?=\\s+person)\",\n",
    "                    r\"\\w+(?=\\s+people)\",\n",
    "                    r\"\\w+(?=\\s+adult)\",\n",
    "                    r\"\\w+(?=\\s+adolescent)\",\n",
    "                    r\"\\w+(?=\\s+child)\",\n",
    "                    r\"\\w+(?=\\s+youth)\",\n",
    "                    r\"\\w+(?=\\s+student)\",\n",
    "                    r\"\\w+(?=\\s+undergraduate)\",\n",
    "                    r\"\\w+(?=\\s+graduate)\",\n",
    "                    r\"\\w+(?=\\s+college)\",\n",
    "                    r\"\\w+(?=\\s+university)\",\n",
    "                    r\"\\w+(?=\\s+patient)\",\n",
    "                    r\"\\w+(?=\\s+medicat)\",\n",
    "                    r\"\\w+(?=\\s+outpatient)\",\n",
    "                    r\"\\w+(?=\\s+veteran)\"]\n",
    "\n",
    "secondary_patterns = [r\"\\w+(?=\\s+female)\",\n",
    "                      r\"\\w+(?=\\s+male)\",\n",
    "                      r\"\\w+(?=\\s+women)\",\n",
    "                      r\"\\w+(?=\\s+men)\",\n",
    "                      r\"\\w+(?=\\s+girl)\",\n",
    "                      r\"\\w+(?=\\s+boy)\",\n",
    "                      r\"\\w+(?=\\s+old)\",\n",
    "                      r\"\\w+(?=\\s+elderly)\",\n",
    "                      r\"\\w+(?=\\s+control)\",\n",
    "                      r\"\\w+(?=\\s+hc)\",\n",
    "                      r\"\\w+(?=\\s+comparison)\",\n",
    "                      r\"\\w+(?=\\s+sighted)\",\n",
    "                      r\"\\w+(?=\\s+hearing)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [\"twenty\", \n",
    "        \"thirty\", \n",
    "        \"forty\", \n",
    "        \"fifty\", \n",
    "        \"sixty\", \n",
    "        \"seventy\", \n",
    "        \"eighty\", \n",
    "        \"ninety\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2float(n):\n",
    "    return float(w2n.word_to_num(n))\n",
    "\n",
    "def matches_to_n(matches, ns, min_n, max_n):\n",
    "    for match in matches:\n",
    "        n = match.strip()\n",
    "        if n.isdigit():\n",
    "            n = float(n)\n",
    "            if n >= min_n and n <= max_n:\n",
    "                ns.append(n)\n",
    "        else: \n",
    "            try:\n",
    "                n = str2float(n)\n",
    "                if n >= min_n and n <= max_n:\n",
    "                    ns.append(n)\n",
    "            except:\n",
    "                for num in nums:\n",
    "                    n = n.replace(num, num + \" \")\n",
    "                try:\n",
    "                    n = str2float(n)\n",
    "                    if n >= min_n and n <= max_n:\n",
    "                        ns.append(n)\n",
    "                except:\n",
    "                    pass\n",
    "    return ns\n",
    "\n",
    "def extract_n_from_file(primary_patterns, secondary_patterns, \n",
    "                        text, pmid2n, pmid, min_n, max_n):\n",
    "    ns, n = [], 0\n",
    "    text = text.lower().replace(\"-\", \"\").replace(\",\", \"\")\n",
    "    for pattern in primary_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        ns = matches_to_n(matches, ns, min_n, max_n)\n",
    "        if len(ns) > 1:\n",
    "            break\n",
    "    if len(ns) == 0:\n",
    "        for pattern in secondary_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            ns = matches_to_n(matches, ns, min_n, max_n)\n",
    "            if len(ns) > 1:\n",
    "                break\n",
    "    if len(set(ns)) == 1:\n",
    "        n = ns[0]\n",
    "    return n\n",
    "\n",
    "def extract_n_from_corpus(primary_patterns, secondary_patterns, \n",
    "                          path, source_name, pmids, found, df, \n",
    "                          min_n=1, max_n=1000):\n",
    "    pmid2n = {}\n",
    "    for i, pmid in enumerate(pmids):\n",
    "        if pmid not in found:\n",
    "            file = \"{}/{}.txt\".format(path, pmid)\n",
    "            if os.path.exists(file):\n",
    "                text = open(file, \"r\").read()\n",
    "                n = extract_n_from_file(primary_patterns, secondary_patterns, \n",
    "                                        text, pmid2n, pmid, min_n, max_n)\n",
    "                if n > 0:\n",
    "                    pmid2n[pmid] = n\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Processed {} documents\".format(i))\n",
    "    for pmid, n in pmid2n.items():\n",
    "        df.loc[df[\"PMID\"] == pmid, \"N\"] = n\n",
    "        df.loc[df[\"PMID\"] == pmid, \"SOURCE\"] = source_name             \n",
    "        found.append(pmid)\n",
    "    print(\"Found data for {} documents\".format(len(pmid2n.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 documents\n",
      "Processed 1000 documents\n",
      "Processed 2000 documents\n",
      "Processed 3000 documents\n",
      "Processed 4000 documents\n",
      "Processed 5000 documents\n",
      "Processed 6000 documents\n",
      "Processed 7000 documents\n",
      "Processed 8000 documents\n",
      "Processed 9000 documents\n",
      "Processed 10000 documents\n",
      "Processed 11000 documents\n",
      "Processed 12000 documents\n",
      "Processed 13000 documents\n",
      "Processed 14000 documents\n",
      "Processed 15000 documents\n",
      "Processed 16000 documents\n",
      "Processed 17000 documents\n",
      "Processed 18000 documents\n",
      "Found data for 3957 documents\n"
     ]
    }
   ],
   "source": [
    "extract_n_from_corpus(primary_patterns, secondary_patterns,\n",
    "                      \"../../../pubmed/abstracts\", \"Abstract\", pmids, found, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 documents\n",
      "Processed 1000 documents\n",
      "Processed 2000 documents\n",
      "Processed 3000 documents\n",
      "Processed 4000 documents\n",
      "Processed 5000 documents\n",
      "Processed 6000 documents\n",
      "Processed 7000 documents\n",
      "Processed 8000 documents\n",
      "Processed 9000 documents\n",
      "Processed 10000 documents\n",
      "Processed 11000 documents\n",
      "Processed 12000 documents\n",
      "Processed 13000 documents\n",
      "Processed 14000 documents\n",
      "Processed 15000 documents\n",
      "Processed 16000 documents\n",
      "Processed 17000 documents\n",
      "Processed 18000 documents\n",
      "Found data for 950 documents\n"
     ]
    }
   ],
   "source": [
    "extract_n_from_corpus(primary_patterns, secondary_patterns, \n",
    "                      \"../../../cogneuro/texts/raw\", \"FullText\", pmids, found, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export worksheet for manual collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[\"SOURCE\"] == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"subjects.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid2subjects = {df[\"PMID\"][i]: df[\"N\"][i] for i in range(len(df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"metadata.csv\", encoding=\"latin-1\")\n",
    "meta[\"N_SUBJECTS\"] = [pmid2subjects[pmid] for pmid in meta[\"PMID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.to_csv(\"metadata.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number from each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullText  950\n",
      "Abstract  3957\n",
      "EHB       9904\n",
      "BrainMap  3344\n"
     ]
    }
   ],
   "source": [
    "for source in [\"FullText\", \"Abstract\", \"EHB\", \"BrainMap\"]:\n",
    "    print(\"{:9s} {}\".format(source, len(df.loc[df[\"SOURCE\"] == source])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ontol]",
   "language": "python",
   "name": "conda-env-ontol-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
